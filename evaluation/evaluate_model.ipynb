{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HebSafeHarbor Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ner_evaluation.ner_eval import collect_named_entities\n",
    "from ner_evaluation.ner_eval import compute_metrics, Evaluator\n",
    "from ner_evaluation.ner_eval import compute_precision_recall_wrapper\n",
    "from ner_evaluation.ner_eval import Entity\n",
    "\n",
    "from hebsafeharbor import HebSafeHarbor\n",
    "\n",
    "from glob import glob\n",
    "import os\n",
    "import logging\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from difflib import SequenceMatcher\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fb_score(precision:float,recall:float,beta:int=2)->float:\n",
    "    '''\n",
    "    Compute F beta score of a model\n",
    "    :param precision: the model's precision score\n",
    "    :param recall: the model's recall score\n",
    "    :param beta: which metric to compute (1 for F1 score, 2 for F2 score etc.)\n",
    "    '''\n",
    "    return (1+(beta**2))*(precision*recall)/(((beta**2)*precision)+recall)\n",
    "\n",
    "def flatten_results(res):\n",
    "    '''\n",
    "    Takes a list of Evaluator outputs and inserts it into a pandas dataframe\n",
    "    :param res: a list of Evaluator results\n",
    "    :returns a pandas dataframe \n",
    "    '''\n",
    "    entity_list = []\n",
    "    for item in res:\n",
    "        for match_type in item['results'].keys():\n",
    "            \n",
    "            for entities in item['results'][match_type]:\n",
    "                item_dict = {}\n",
    "                item_dict['idx'] = item['idx']\n",
    "                item_dict['match_type'] = match_type\n",
    "                if match_type =='spurious':\n",
    "                    item_dict['pred_entity'] = entities.e_type\n",
    "                    item_dict['pred_start'] = entities.start_offset\n",
    "                    item_dict['pred_end'] = entities.end_offset\n",
    "                elif match_type =='missed':\n",
    "                    item_dict['true_entity'] = entities.e_type\n",
    "                    item_dict['true_start'] = entities.start_offset\n",
    "                    item_dict['true_end'] = entities.end_offset\n",
    "                else:\n",
    "                    item_dict['pred_entity'] = entities[1].e_type\n",
    "                    item_dict['pred_start'] = entities[1].start_offset\n",
    "                    item_dict['pred_end'] = entities[1].end_offset\n",
    "                    item_dict['true_entity'] = entities[0].e_type\n",
    "                    item_dict['true_start'] = entities[0].start_offset\n",
    "                    item_dict['true_end'] = entities[0].end_offset\n",
    "                entity_list.append(item_dict)\n",
    "    return entity_list\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotation_date = \"08-03-2022\"\n",
    "folders = glob(f\"/Users/ayabellicha/Documents/phi_evaluation_set/phi_annotations_{annotation_date}/*/\", recursive = True)\n",
    "annotations_list = []\n",
    "txt_list = []\n",
    "i=0\n",
    "idx_to_folder = {}\n",
    "for folder in folders:\n",
    "    annotations_fname = glob(f\"{folder}*.ann\", recursive = True)[0]\n",
    "    idx_to_folder[i] = '/'.join(annotations_fname.split('/')[-3:-1])\n",
    "    txt_fname = glob(f\"{folder}*.txt\", recursive = True)[0]\n",
    "\n",
    "    with open(annotations_fname) as f:\n",
    "        annotations_list.append(f.readlines())\n",
    "\n",
    "    with open(txt_fname) as f:\n",
    "        txt_list.append(' '.join(f.readlines()))\n",
    "\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run HebSafeHarbor NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.CRITICAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ayabellicha/opt/anaconda3/envs/safeharbor/lib/python3.8/site-packages/torch/autocast_mode.py:141: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
     ]
    }
   ],
   "source": [
    "doc_list = [{\"text\": txt} for txt in txt_list]\n",
    "hebrew_phi = HebSafeHarbor()\n",
    "output = hebrew_phi(doc_list);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Map Entity Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Annotated entity types to include in the analysis\n",
    "monitored_entities = ['ETHNICITY','NAME','ADDRESS','DATE','PHONE_OR_FAX','ID','EMAIL','URL','IP_ADDRESS','ORGANIZATION']\n",
    "\n",
    "#annot_entity_mapping = {'SOCIAL_STATUS':'ORG','CARE_ENVIRONMENT':'ORG','ADDRESS':'LOC'}\n",
    "annot_entity_mapping = {'ADDRESS':'LOC','ORGANIZATION':'ORG'}\n",
    "sh_entity_mapping = {'MEDICAL_DATE':'DATE','BIRTH_DATE':'DATE','CITY':'LOC','COUNTRY':'LOC',\n",
    "                     'EMAIL_ADDRESS':'EMAIL','ISRAELI_ID_NUMBER':'ID','PER':'NAME','PERS':'NAME',\n",
    "                     'PHONE_NUMBER':'PHONE_OR_FAX','FAC':'LOC','GPE':'LOC','MISC__AFF':'ETHNICITY'}\n",
    "\n",
    "# Entity types included in the analysis\n",
    "tags = ['LOC','EMAIL','ID','ORG','DATE','NAME','ETHNICITY','PHONE_OR_FAX','URL','IP_ADDRESS'] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Entity Lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_predictions = []\n",
    "for prediction in output:\n",
    "    predicted_entity_list = []\n",
    "    for entity in prediction.granular_analyzer_results:\n",
    "        entity_dict = entity.__dict__\n",
    "        entity_type = sh_entity_mapping.get(entity_dict['entity_type'],entity_dict['entity_type'])\n",
    "        predicted_entity_list.append(Entity(entity_type,entity_dict['start'],entity_dict['end']))\n",
    "    agg_predictions.append(predicted_entity_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "annotations = annotations_list[0]\n",
    "agg_true = []\n",
    "for annotations in annotations_list:\n",
    "    entity_list = []\n",
    "    for a in annotations:\n",
    "        entity = re.split('\\t|\\n|\\s',a) \n",
    "        if (len(entity[0])<1) or (entity[0][0]!='T') or not(entity[1] in monitored_entities):\n",
    "            continue\n",
    "        entity_type = annot_entity_mapping.get(entity[1],entity[1])\n",
    "        entity_list.append(Entity(entity_type,int(entity[2]),int(entity[3])))\n",
    "    agg_true.append(entity_list)\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Model Evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = Evaluator(agg_true,agg_predictions,tags)\n",
    "metrics = evaluator.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a dataframe containing the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "examples = flatten_results(metrics[2])\n",
    "entities_df = pd.DataFrame(examples)\n",
    "\n",
    "entities_df['pred_text'] = entities_df.apply(lambda x: txt_list[x['idx']][int(x['pred_start']):int(x['pred_end'])] if x['pred_entity'] is not np.nan else None,axis=1)\n",
    "entities_df['true_text'] = entities_df.apply(lambda x: txt_list[x['idx']][int(x['true_start']):int(x['true_end'])] if x['true_entity'] is not np.nan else None,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Match type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "strict      530\n",
       "type        139\n",
       "spurious     72\n",
       "missed       57\n",
       "partial      43\n",
       "exact        36\n",
       "Name: match_type, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entities_df['match_type'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifications and Misclassifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pred_entity   true_entity \n",
       "DATE          DATE            121\n",
       "EMAIL         EMAIL            24\n",
       "ETHNICITY     ETHNICITY        12\n",
       "              ORG               1\n",
       "ID            DATE              2\n",
       "              ID              138\n",
       "              LOC               9\n",
       "              PHONE_OR_FAX     18\n",
       "LOC           ETHNICITY         1\n",
       "              LOC             101\n",
       "              ORG              18\n",
       "NAME          ETHNICITY         1\n",
       "              LOC               1\n",
       "              NAME            182\n",
       "              ORG               8\n",
       "ORG           DATE              3\n",
       "              LOC               8\n",
       "              NAME              8\n",
       "              ORG              84\n",
       "PHONE_OR_FAX  PHONE_OR_FAX      2\n",
       "URL           EMAIL             1\n",
       "              URL               5\n",
       "Name: idx, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entities_df[(entities_df.match_type != 'spurious') & (entities_df.match_type != 'missed')].groupby(['pred_entity','true_entity'])['idx'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## F2-Score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The evaluator's built in metrics\n",
    "The metric penalized partial matches at 50%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ent_type F2 score:  0.827970297029703\n",
      "partial F2 score:  0.8131188118811882\n",
      "strict F2 score:  0.6559405940594059\n",
      "exact F2 score:  0.7004950495049505\n"
     ]
    }
   ],
   "source": [
    "f2_dict = {}\n",
    "f2_dict['semeval'] = {}\n",
    "for k in metrics[0].keys():\n",
    "    print(f'{k} F2 score: ',fb_score(metrics[0][k]['precision'],metrics[0][k]['recall']))\n",
    "    f2_dict['semeval'][k] = fb_score(metrics[0][k]['precision'],metrics[0][k]['recall'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Give partial matches an equal weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Partial F2 score: 0.9257425742574259\n"
     ]
    }
   ],
   "source": [
    "TP = entities_df[~entities_df['match_type'].isin(['spurious','missed'])].shape[0]\n",
    "FP = entities_df[entities_df['match_type'].isin(['spurious'])].shape[0]\n",
    "FN = entities_df[entities_df['match_type'].isin(['missed'])].shape[0]\n",
    "\n",
    "precision = TP/(TP+FP)\n",
    "recall = TP/(TP+FN)\n",
    "print(f'Partial F2 score: {fb_score(precision=precision,recall=recall)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "f2_dict['equal_weight'] = {}\n",
    "f2_dict['equal_weight']['partial'] = fb_score(precision=precision,recall=recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weighted F2 score \n",
    "Weight partial matches according to their overlap ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted partial F2 score: 0.9190370169212858\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tp_df = entities_df[~entities_df['match_type'].isin(['spurious','missed'])].copy()\n",
    "tp_df['weight'] = tp_df.apply(lambda x: SequenceMatcher(None,x['pred_text'],x['true_text']).ratio(),axis=1)\n",
    "weighted_TP = tp_df['weight'].sum()\n",
    "precision = weighted_TP/(weighted_TP+FP)\n",
    "recall = weighted_TP/(weighted_TP+FN)\n",
    "fb_score(precision=precision,recall=recall)\n",
    "print(f'Weighted partial F2 score: {fb_score(precision=precision,recall=recall)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "f2_dict['weighted_score'] = {}\n",
    "f2_dict['weighted_score']['partial'] = fb_score(precision=precision,recall=recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "f2_df = pd.DataFrame(f2_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Match types by predicted entity type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pred_entity</th>\n",
       "      <th>match_type</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">DATE</th>\n",
       "      <th>strict</th>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spurious</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>type</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EMAIL</th>\n",
       "      <th>strict</th>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">ETHNICITY</th>\n",
       "      <th>strict</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spurious</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>type</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>partial</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">ID</th>\n",
       "      <th>strict</th>\n",
       "      <td>138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exact</th>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>partial</th>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spurious</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">LOC</th>\n",
       "      <th>type</th>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>strict</th>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>partial</th>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spurious</th>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exact</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">NAME</th>\n",
       "      <th>strict</th>\n",
       "      <td>166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>type</th>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>partial</th>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exact</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spurious</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">ORG</th>\n",
       "      <th>type</th>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spurious</th>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>strict</th>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>partial</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exact</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PHONE_OR_FAX</th>\n",
       "      <th>strict</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">URL</th>\n",
       "      <th>strict</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exact</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spurious</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         count\n",
       "pred_entity  match_type       \n",
       "DATE         strict        116\n",
       "             spurious        5\n",
       "             type            5\n",
       "EMAIL        strict         24\n",
       "ETHNICITY    strict         10\n",
       "             spurious        5\n",
       "             type            2\n",
       "             partial         1\n",
       "ID           strict        138\n",
       "             exact          21\n",
       "             partial         8\n",
       "             spurious        1\n",
       "LOC          type           70\n",
       "             strict         31\n",
       "             partial        16\n",
       "             spurious       14\n",
       "             exact           3\n",
       "NAME         strict        166\n",
       "             type           16\n",
       "             partial         8\n",
       "             exact           2\n",
       "             spurious        1\n",
       "ORG          type           46\n",
       "             spurious       45\n",
       "             strict         38\n",
       "             partial        10\n",
       "             exact           9\n",
       "PHONE_OR_FAX strict          2\n",
       "URL          strict          5\n",
       "             exact           1\n",
       "             spurious        1"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entities_df.groupby(['pred_entity','match_type'])['idx'].count().reset_index().rename(columns={'idx':'count'}).sort_values(['pred_entity','count'],ascending=[True,False]).set_index(['pred_entity','match_type'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Match types by annotated entity type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>true_entity</th>\n",
       "      <th>match_type</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">DATE</th>\n",
       "      <th>strict</th>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>type</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>partial</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exact</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">EMAIL</th>\n",
       "      <th>strict</th>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exact</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">ETHNICITY</th>\n",
       "      <th>strict</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>type</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exact</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>partial</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">ID</th>\n",
       "      <th>strict</th>\n",
       "      <td>138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>missed</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">LOC</th>\n",
       "      <th>type</th>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>strict</th>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>partial</th>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>missed</th>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exact</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">NAME</th>\n",
       "      <th>strict</th>\n",
       "      <td>166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>missed</th>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>type</th>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exact</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>partial</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">ORG</th>\n",
       "      <th>type</th>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>strict</th>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>partial</th>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>missed</th>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exact</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">PHONE_OR_FAX</th>\n",
       "      <th>exact</th>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>missed</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>strict</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>URL</th>\n",
       "      <th>strict</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         count\n",
       "true_entity  match_type       \n",
       "DATE         strict        116\n",
       "             type            5\n",
       "             partial         3\n",
       "             exact           2\n",
       "EMAIL        strict         24\n",
       "             exact           1\n",
       "ETHNICITY    strict         10\n",
       "             type            2\n",
       "             exact           1\n",
       "             partial         1\n",
       "ID           strict        138\n",
       "             missed          2\n",
       "LOC          type           70\n",
       "             strict         31\n",
       "             partial        14\n",
       "             missed         12\n",
       "             exact           4\n",
       "NAME         strict        166\n",
       "             missed         27\n",
       "             type           16\n",
       "             exact           6\n",
       "             partial         2\n",
       "ORG          type           46\n",
       "             strict         38\n",
       "             partial        23\n",
       "             missed         12\n",
       "             exact           4\n",
       "PHONE_OR_FAX exact          18\n",
       "             missed          4\n",
       "             strict          2\n",
       "URL          strict          5"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entities_df.groupby(['true_entity','match_type'])['idx'].count().reset_index().rename(columns={'idx':'count'}).sort_values(['true_entity','count'],ascending=[True,False]).set_index(['true_entity','match_type'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spurious Entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dl/j54t3drs0fz72zt68qq4vxb80000gn/T/ipykernel_56358/812370801.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  spurious_df['pred_context'] = spurious_df.apply(lambda x: txt_list[x['idx']][(max(0,int(x['pred_start'])-50)):(int(x['pred_end'])+50)],axis=1)\n"
     ]
    }
   ],
   "source": [
    "spurious_df = entities_df[entities_df['match_type']=='spurious']\n",
    "spurious_df['pred_context'] = spurious_df.apply(lambda x: txt_list[x['idx']][(max(0,int(x['pred_start'])-50)):(int(x['pred_end'])+50)],axis=1)\n",
    "spurious_df = spurious_df.groupby(['pred_entity','idx'])[['pred_text','pred_context']].agg(list).reset_index() #.to_csv('spurious.csv',encoding = 'utf-8-sig')\n",
    "\n",
    "spurious_df['folder_name'] = spurious_df['idx'].apply(lambda x: '/'.join(folders[x].split('/')[-3:]))\n",
    "#spurious_df\n",
    "spurious_df.to_csv('spurious.csv',encoding = 'utf-8-sig')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missed Entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dl/j54t3drs0fz72zt68qq4vxb80000gn/T/ipykernel_56358/3060490070.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  missed_df['true_context'] = missed_df.apply(lambda x: txt_list[x['idx']][(max(0,int(x['true_start'])-50)):(int(x['true_end'])+50)],axis=1)\n"
     ]
    }
   ],
   "source": [
    "missed_df = entities_df[entities_df['match_type']=='missed']\n",
    "missed_df['true_context'] = missed_df.apply(lambda x: txt_list[x['idx']][(max(0,int(x['true_start'])-50)):(int(x['true_end'])+50)],axis=1)\n",
    "missed_df = missed_df.groupby(['true_entity','idx'])[['true_text','true_context']].agg(list).reset_index() #.to_csv('spurious.csv',encoding = 'utf-8-sig')\n",
    "\n",
    "missed_df['folder_name'] = missed_df['idx'].apply(lambda x: '/'.join(folders[x].split('/')[-3:]))\n",
    "#spurious_df\n",
    "missed_df.to_csv('missed.csv',encoding = 'utf-8-sig')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Misclassifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dl/j54t3drs0fz72zt68qq4vxb80000gn/T/ipykernel_56358/2318224368.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  missclass_df['true_context'] = missclass_df.apply(lambda x: txt_list[x['idx']][(max(0,int(x['true_start'])-50)):(int(x['true_end'])+50)],axis=1)\n",
      "/var/folders/dl/j54t3drs0fz72zt68qq4vxb80000gn/T/ipykernel_56358/2318224368.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  missclass_df['pred_context'] = missclass_df.apply(lambda x: txt_list[x['idx']][(max(0,int(x['pred_start'])-50)):(int(x['pred_end'])+50)],axis=1)\n",
      "/var/folders/dl/j54t3drs0fz72zt68qq4vxb80000gn/T/ipykernel_56358/2318224368.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  missclass_df['folder_name'] = missclass_df['idx'].apply(lambda x: '/'.join(folders[x].split('/')[-3:]))\n"
     ]
    }
   ],
   "source": [
    "missclass_df = entities_df[(entities_df['match_type']!='missed') & (entities_df['match_type']!='spurious') & (entities_df['pred_entity']!=entities_df['true_entity'])]\n",
    "missclass_df['true_context'] = missclass_df.apply(lambda x: txt_list[x['idx']][(max(0,int(x['true_start'])-50)):(int(x['true_end'])+50)],axis=1)\n",
    "missclass_df['pred_context'] = missclass_df.apply(lambda x: txt_list[x['idx']][(max(0,int(x['pred_start'])-50)):(int(x['pred_end'])+50)],axis=1)\n",
    "#missclass_df = missed_df.groupby(['true_entity','pred_entity','idx'])[['true_text','true_context']].agg(list).reset_index() #.to_csv('spurious.csv',encoding = 'utf-8-sig')\n",
    "\n",
    "missclass_df['folder_name'] = missclass_df['idx'].apply(lambda x: '/'.join(folders[x].split('/')[-3:]))\n",
    "missclass_df = missclass_df.sort_values(['idx','match_type','true_entity','pred_entity'])[['idx','match_type','pred_entity','true_entity','pred_text','true_text','true_context','folder_name']]\n",
    "#spurious_df\n",
    "missclass_df.to_csv('missclass.csv',encoding = 'utf-8-sig')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partial Matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dl/j54t3drs0fz72zt68qq4vxb80000gn/T/ipykernel_56358/2191129170.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  partial_df['true_context'] = partial_df.apply(lambda x: txt_list[x['idx']][(max(0,int(x['true_start'])-50)):(int(x['true_end'])+50)],axis=1)\n",
      "/var/folders/dl/j54t3drs0fz72zt68qq4vxb80000gn/T/ipykernel_56358/2191129170.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  partial_df['pred_context'] = partial_df.apply(lambda x: txt_list[x['idx']][(max(0,int(x['pred_start'])-50)):(int(x['pred_end'])+50)],axis=1)\n",
      "/var/folders/dl/j54t3drs0fz72zt68qq4vxb80000gn/T/ipykernel_56358/2191129170.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  partial_df['folder_name'] = partial_df['idx'].apply(lambda x: '/'.join(folders[x].split('/')[-3:]))\n"
     ]
    }
   ],
   "source": [
    "partial_df = entities_df[(entities_df['match_type']=='type')]\n",
    "partial_df['true_context'] = partial_df.apply(lambda x: txt_list[x['idx']][(max(0,int(x['true_start'])-50)):(int(x['true_end'])+50)],axis=1)\n",
    "partial_df['pred_context'] = partial_df.apply(lambda x: txt_list[x['idx']][(max(0,int(x['pred_start'])-50)):(int(x['pred_end'])+50)],axis=1)\n",
    "#missclass_df = missed_df.groupby(['true_entity','pred_entity','idx'])[['true_text','true_context']].agg(list).reset_index() #.to_csv('spurious.csv',encoding = 'utf-8-sig')\n",
    "\n",
    "partial_df['folder_name'] = partial_df['idx'].apply(lambda x: '/'.join(folders[x].split('/')[-3:]))\n",
    "partial_df = partial_df.sort_values(['idx','match_type','true_entity','pred_entity'])[['idx','match_type','pred_entity','true_entity','pred_text','true_text','true_context','folder_name']]\n",
    "#spurious_df\n",
    "partial_df.to_csv('partial.csv',encoding = 'utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['6']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#files = glob(f\"/Users/ayabellicha/Documents/HebSafeHarbor/evaluation/*\", recursive = True)\n",
    "\n",
    "#fname = glob(f\"{folder}*.ann\", recursive = True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "mkdir: results: File exists\n"
     ]
    }
   ],
   "source": [
    "!mkdir results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "files = glob(f\"{os.getcwd()}/results/FP_and_FN_{annotation_date}*\")\n",
    "if len(files)>0 and len(re.findall(r'_v(\\d).xlsx',files[0]))>0:\n",
    "    version = max(np.array([int(re.findall(r'_v(\\d).xlsx',x)[0])+1 for x in files]))\n",
    "else:\n",
    "    version = 1\n",
    "\n",
    "options = {}\n",
    "options['strings_to_formulas'] = False\n",
    "options['strings_to_urls'] = False\n",
    "\n",
    "with pd.ExcelWriter(f'results/FP_and_FN_{annotation_date}_v{version}.xlsx',engine='xlsxwriter',engine_kwargs={'options':options}) as writer:\n",
    "    f2_df.to_excel(writer,sheet_name='F2 score',index=True,encoding = 'utf-8-sig')\n",
    "    spurious_df.to_excel(writer,sheet_name='FP',index=False,encoding = 'utf-8-sig')\n",
    "    missed_df.to_excel(writer,sheet_name='FN',index=False,encoding = 'utf-8-sig')\n",
    "    missclass_df.to_excel(writer,sheet_name='Misclassification',index=False,encoding = 'utf-8-sig')\n",
    "    partial_df.to_excel(writer,sheet_name='Partial match',index=False,encoding = 'utf-8-sig')\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e2eff9bcfdf21d0f3bb31cf955d39a41efec3a545160fb6b7dfb0e4f717592eb"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
